{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the objective is \n",
    "```\n",
    "Ajusta o modelo log√≠stico para cada uma dessas 5 redes e me manda duas tabelas.\n",
    "\n",
    "Na primeira tabela vc coloca 5 linhas, uma para cada rede, e\n",
    "1. na primeira coluna coloca os par√¢metros estimados\n",
    "2. na segunda coluna coloca os hops ajustados\n",
    "3. na terceira coluna em diante coloca n√∫mero de v√©rtices, arestas, e outras medidas estruturais, como centralidades\n",
    "\n",
    "A segunda tabela tem dimens√µes 5 x 5, mas basta preencher a triangular superior.\n",
    "Voc√™ coloca os p-valores do teste ANOVA entre os par√¢metros dessas 5 redes comparando dois a dois, ou seja, 10 p-valores\n",
    "\n",
    "Vou ver se conseguimos montar uma historinha com isso.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "#Graph imports\n",
    "import src.graph as graph\n",
    "import src.logit_estimator as estimator\n",
    "import src.utils as utils\n",
    "import src.model_selection as model_selection\n",
    "import src.gic as gic\n",
    "import src.param_estimator as pe\n",
    "import src.graph as graph\n",
    "import src.model_selection as ms\n",
    "\n",
    "# usual imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import random\n",
    "import networkx as nx\n",
    "from numpy import errstate\n",
    "\n",
    "from IPython.display import display\n",
    "from pyvis.network import Network\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected networks for analysis:\n",
      "1. c.elegans_neural.male_1.graphml\n",
      "2. p.pacificus_neural.synaptic_1.graphml\n",
      "3. mouse_visual.cortex_1.graphml\n",
      "4. rhesus_brain_1.graphml\n",
      "5. mixed.species_brain_1.graphml\n",
      "\n",
      "Total files available: 18\n",
      "Selected files for analysis: 5\n"
     ]
    }
   ],
   "source": [
    "PATH = f'../data/connectomes/'\n",
    "DATASET = f'.'\n",
    "\n",
    "files = sorted(os.listdir(PATH+DATASET))\n",
    "# select only the files that end with .graphml\n",
    "files = [f for f in files if f.endswith('.graphml')]\n",
    "\n",
    "# Select 5 networks of different species for analysis\n",
    "selected_networks = [\n",
    "    'c.elegans_neural.male_1.graphml',     # C. elegans\n",
    "    'p.pacificus_neural.synaptic_1.graphml',  # P. pacificus  \n",
    "    'mouse_visual.cortex_1.graphml',       # Mouse\n",
    "    'rhesus_brain_1.graphml',              # Rhesus macaque\n",
    "    'mixed.species_brain_1.graphml'        # Mixed species\n",
    "]\n",
    "\n",
    "print(\"Selected networks for analysis:\")\n",
    "for i, network in enumerate(selected_networks, 1):\n",
    "    print(f\"{i}. {network}\")\n",
    "\n",
    "print(f\"\\nTotal files available: {len(files)}\")\n",
    "print(f\"Selected files for analysis: {len(selected_networks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.digraph.DiGraph at 0x13ba8ceb0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs = [nx.read_graphml(PATH+DATASET+'/'+file) for file in selected_networks]\n",
    "graphs = graphs[:1]\n",
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit_graph(real_graph, d, n_iteration, warm_up, patience, dist_type='KL', edge_delta=None, min_gic_threshold=None, verbose=True):\n",
    "   \"\"\"\n",
    "   Estimates parameters, generates a graph using the Logit Graph model,\n",
    "   and calculates GIC, allowing for different convergence criteria.\n",
    "\n",
    "   Args:\n",
    "       real_graph (nx.Graph or np.ndarray): The target graph.\n",
    "       d (int): Parameter for the Logit model (number of neighbors).\n",
    "       n_iteration (int): Maximum number of iterations for graph generation.\n",
    "       warm_up (int): Number of initial iterations to discard.\n",
    "       patience (int): Number of iterations to wait for improvement before stopping.\n",
    "       dist_type (str): Distance type for GIC ('KL', 'L1', 'L2').\n",
    "       convergence_criteria (str): Criterion for stopping ('spectrum' or 'spectrum_and_edges').\n",
    "\n",
    "   Returns:\n",
    "       tuple: Contains the best generated graph, sigma, GIC values,\n",
    "              spectrum differences, edge differences, best iteration index, and all graphs.\n",
    "   \"\"\"\n",
    "   # Ensure real_graph is a NumPy array\n",
    "   if isinstance(real_graph, nx.Graph):\n",
    "       real_graph = nx.to_numpy_array(real_graph)\n",
    "\n",
    "   # Estimation\n",
    "   est = estimator.LogitRegEstimator(real_graph, d=d)\n",
    "   features, labels = est.get_features_labels()\n",
    "   # Using default L1 regularization as before, adjust if needed\n",
    "   result, params, pvalue = est.estimate_parameters(l1_wt=1, alpha=0, features=features, labels=labels)\n",
    "   sigma = params[0]\n",
    "\n",
    "   # Generation\n",
    "   n = real_graph.shape[0]\n",
    "\n",
    "   params_dict = {\n",
    "      \"n\": n,\n",
    "      \"d\": d,\n",
    "      \"sigma\": sigma,\n",
    "      \"n_iteration\": n_iteration,\n",
    "      \"warm_up\": warm_up,\n",
    "      \"patience\": patience,\n",
    "      \"edge_delta\": edge_delta,\n",
    "   }\n",
    "\n",
    "   graph_model = graph.GraphModel(n=n, d=d, sigma=sigma)\n",
    "\n",
    "   print(f\"Running generation with convergence criterion: {edge_delta}\")\n",
    "   \n",
    "   graphs, spec, spectrum_diffs, best_iteration, best_graph_arr = graph_model.populate_edges_spectrum_min_gic(\n",
    "        max_iterations=n_iteration,\n",
    "        # warm_up=warm_up,\n",
    "        patience=patience,\n",
    "        real_graph=real_graph,\n",
    "        edge_delta=edge_delta,\n",
    "        min_gic_threshold=min_gic_threshold,\n",
    "        gic_dist_type=dist_type,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "\n",
    "   print(f\"Finish generation with convergence criterion: {edge_delta}\")\n",
    "   # Calculate edge differences\n",
    "   real_edges = np.sum(real_graph) / 2\n",
    "   edge_diffs = [abs(np.sum(g) / 2 - real_edges) for g in graphs]\n",
    "\n",
    "   # Use the best graph found based on the selected criteria/iteration\n",
    "   # best_graph = graphs[best_iteration]\n",
    "\n",
    "   # Calculate GIC for the best graph\n",
    "   best_graph_nx = nx.from_numpy_array(best_graph_arr)\n",
    "   gic_value = gic.GraphInformationCriterion(\n",
    "       graph=nx.from_numpy_array(real_graph),\n",
    "       log_graph=best_graph_nx,\n",
    "       model='LG',\n",
    "       dist_type=dist_type\n",
    "   ).calculate_gic()\n",
    "\n",
    "   return best_graph_arr, sigma, [gic_value], spectrum_diffs, edge_diffs, best_iteration, graphs\n",
    "\n",
    "def fit_logit_graphs_to_dataset(graphs, n_graphs=5, sim_params=None):\n",
    "    \"\"\"\n",
    "    Fit logit graph models to the first n graphs in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graphs : list\n",
    "        List of NetworkX graphs\n",
    "    n_graphs : int\n",
    "        Number of graphs to process\n",
    "    sim_params : dict\n",
    "        Simulation parameters for logit graph fitting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing original graphs, fitted graphs, and GIC values\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'original_graphs': [],\n",
    "        'fitted_graphs': [],\n",
    "        'gic_values': [],\n",
    "        'fit_success': [],\n",
    "        'graph_stats': []\n",
    "    }\n",
    "    \n",
    "    n_graphs = min(n_graphs, len(graphs))\n",
    "    \n",
    "    for i in range(n_graphs):\n",
    "        print(f\"\\n{'='*20} Processing Graph {i+1}/{n_graphs} {'='*20}\")\n",
    "        \n",
    "        original_graph = graphs[i]\n",
    "        adj_matrix = nx.to_numpy_array(original_graph)\n",
    "        n_nodes = original_graph.number_of_nodes()\n",
    "        n_edges = original_graph.number_of_edges()\n",
    "        \n",
    "        print(f\"Original graph - Nodes: {n_nodes}, Edges: {n_edges}\")\n",
    "        \n",
    "        # Fit logit graph model\n",
    "        best_gic_value = float('inf')\n",
    "        for d in range(1, 3):\n",
    "            logit_results = get_logit_graph(\n",
    "                real_graph=adj_matrix.copy(),\n",
    "                d=d,\n",
    "                n_iteration=sim_params[\"n_iteration\"],\n",
    "                warm_up=sim_params[\"warm_up\"],\n",
    "                patience=sim_params[\"patience\"],\n",
    "                dist_type=sim_params[\"dist_type\"],\n",
    "                edge_delta=None,  # Use spectrum convergence only\n",
    "                min_gic_threshold=sim_params[\"min_gic_threshold\"],\n",
    "                verbose=sim_params[\"verbose\"],\n",
    "            )\n",
    "            gic_value = logit_results[2][0]\n",
    "            if gic_value < best_gic_value:\n",
    "                best_gic_value = gic_value\n",
    "                best_iteration = logit_results[5]\n",
    "                best_d = d\n",
    "                fitted_adj_matrix = logit_results[0]\n",
    "                fitted_graph = nx.from_numpy_array(fitted_adj_matrix)\n",
    "        \n",
    "        results['original_graphs'].append(original_graph)\n",
    "        results['fitted_graphs'].append(fitted_graph)\n",
    "        results['gic_values'].append(best_gic_value)\n",
    "        results['fit_success'].append(True)\n",
    "        results['best_d'].append(best_d)\n",
    "        results['graph_stats'].append({\n",
    "            'original_nodes': n_nodes,\n",
    "            'original_edges': n_edges,\n",
    "            'fitted_nodes': fitted_graph.number_of_nodes(),\n",
    "            'fitted_edges': fitted_graph.number_of_edges(),\n",
    "            'best_iteration': best_iteration\n",
    "        })\n",
    "        \n",
    "        print(f\"Fitting successful - GIC: {best_gic_value:.4f}, Best iteration: {best_iteration}\")\n",
    "        print(f\"Fitted graph - Nodes: {fitted_graph.number_of_nodes()}, Edges: {fitted_graph.number_of_edges()}\")\n",
    "        gc.collect()  # Clean up memory\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting logit graph fitting experiment...\n",
      "\n",
      "==================== Processing Graph 1/1 ====================\n",
      "Original graph - Nodes: 272, Edges: 4451\n",
      "Running generation with convergence criterion: None\n",
      "iteration: 0\n",
      "\t Current GIC (KL): inf (Threshold: 5)\n",
      "\t Best Spectrum Diff: inf\n",
      "\t Patience: 0/1500\n",
      "\t Current edges: 0.0 (Real edges: 1981.0)\n"
     ]
    }
   ],
   "source": [
    "# Define simulation parameters for faster computation on multiple graphs\n",
    "sim_params = {\n",
    "    \"n_iteration\": 8000,   # Reduced for faster computation\n",
    "    \"warm_up\": 500,\n",
    "    \"patience\": 1500,      # Reduced patience\n",
    "    \"dist_type\": 'KL',\n",
    "    \"min_gic_threshold\": 5,\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "# Updated fit_logit_graphs_to_dataset function to properly return sigma and d values\n",
    "def fit_logit_graphs_to_dataset_improved(graphs, n_graphs=5, sim_params=None):\n",
    "    \"\"\"\n",
    "    Fit logit graph models to the selected graphs and extract network features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graphs : list\n",
    "        List of NetworkX graphs\n",
    "    n_graphs : int\n",
    "        Number of graphs to process\n",
    "    sim_params : dict\n",
    "        Simulation parameters for logit graph fitting\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results : list\n",
    "        List of dictionaries containing results for each network\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    n_graphs = min(n_graphs, len(graphs))\n",
    "    \n",
    "    for i in range(n_graphs):\n",
    "        print(f\"\\n{'='*20} Processing Graph {i+1}/{n_graphs} {'='*20}\")\n",
    "        \n",
    "        original_graph = graphs[i]\n",
    "        adj_matrix = nx.to_numpy_array(original_graph)\n",
    "        n_nodes = original_graph.number_of_nodes()\n",
    "        n_edges = original_graph.number_of_edges()\n",
    "        \n",
    "        print(f\"Original graph - Nodes: {n_nodes}, Edges: {n_edges}\")\n",
    "        \n",
    "        # Test different d values and find the best one based on GIC\n",
    "        best_gic_value = float('inf')\n",
    "        best_d = 0\n",
    "        best_sigma = None\n",
    "        best_fitted_graph = None\n",
    "        \n",
    "        for d in range(3):  # Test d = 0, 1, 2\n",
    "            try:\n",
    "                logit_results = get_logit_graph(\n",
    "                    real_graph=adj_matrix.copy(),\n",
    "                    d=d,\n",
    "                    n_iteration=sim_params[\"n_iteration\"],\n",
    "                    warm_up=sim_params[\"warm_up\"],\n",
    "                    patience=sim_params[\"patience\"],\n",
    "                    dist_type=sim_params[\"dist_type\"],\n",
    "                    edge_delta=None,\n",
    "                    min_gic_threshold=sim_params[\"min_gic_threshold\"],\n",
    "                    verbose=sim_params[\"verbose\"],\n",
    "                )\n",
    "                \n",
    "                fitted_adj_matrix, sigma, gic_values, spectrum_diffs, edge_diffs, best_iteration, all_graphs = logit_results\n",
    "                gic_value = gic_values[0]\n",
    "                \n",
    "                print(f\"  d={d}: sigma={sigma:.4f}, GIC={gic_value:.4f}\")\n",
    "                \n",
    "                if gic_value < best_gic_value:\n",
    "                    best_gic_value = gic_value\n",
    "                    best_d = d\n",
    "                    best_sigma = sigma\n",
    "                    best_fitted_graph = nx.from_numpy_array(fitted_adj_matrix)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error with d={d}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if best_fitted_graph is None:\n",
    "            print(f\"Failed to fit any model for graph {i+1}\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate centrality measures and network features\n",
    "        degree_centrality = np.mean(list(nx.degree_centrality(original_graph).values()))\n",
    "        \n",
    "        # Handle potential issues with centrality calculations for disconnected graphs\n",
    "        if nx.is_connected(original_graph):\n",
    "            betweenness_centrality = np.mean(list(nx.betweenness_centrality(original_graph).values()))\n",
    "            closeness_centrality = np.mean(list(nx.closeness_centrality(original_graph).values()))\n",
    "        else:\n",
    "            # For disconnected graphs, calculate on largest component\n",
    "            largest_cc = max(nx.connected_components(original_graph), key=len)\n",
    "            subgraph = original_graph.subgraph(largest_cc)\n",
    "            betweenness_centrality = np.mean(list(nx.betweenness_centrality(subgraph).values()))\n",
    "            closeness_centrality = np.mean(list(nx.closeness_centrality(subgraph).values()))\n",
    "        \n",
    "        clustering_coeff = nx.average_clustering(original_graph)\n",
    "        \n",
    "        # Additional network features\n",
    "        density = nx.density(original_graph)\n",
    "        transitivity = nx.transitivity(original_graph)\n",
    "        \n",
    "        # Degree statistics\n",
    "        degrees = [d for n, d in original_graph.degree()]\n",
    "        avg_degree = np.mean(degrees)\n",
    "        max_degree = np.max(degrees)\n",
    "        \n",
    "        result = {\n",
    "            'network': selected_networks[i],\n",
    "            'sigma': best_sigma,\n",
    "            'd_parameter': best_d,\n",
    "            'n_vertices': n_nodes,\n",
    "            'n_edges': n_edges,\n",
    "            'gic_value': best_gic_value,\n",
    "            'degree_centrality': degree_centrality,\n",
    "            'betweenness_centrality': betweenness_centrality,\n",
    "            'closeness_centrality': closeness_centrality,\n",
    "            'clustering_coeff': clustering_coeff,\n",
    "            'density': density,\n",
    "            'transitivity': transitivity,\n",
    "            'avg_degree': avg_degree,\n",
    "            'max_degree': max_degree,\n",
    "            'fitted_graph': best_fitted_graph,\n",
    "            'original_graph': original_graph\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        print(f\"‚úì Successfully fitted model for {selected_networks[i]}\")\n",
    "        print(f\"  - Sigma: {best_sigma:.4f}\")\n",
    "        print(f\"  - d parameter (Hops Ajustados): {best_d}\")\n",
    "        print(f\"  - Vertices: {n_nodes}, Edges: {n_edges}\")\n",
    "        print(f\"  - GIC: {best_gic_value:.4f}\")\n",
    "        \n",
    "        gc.collect()  # Clean up memory\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Fit logit graphs to all 5 networks\n",
    "print(\"Starting logit graph fitting experiment...\")\n",
    "results = fit_logit_graphs_to_dataset_improved(graphs, n_graphs=1, sim_params=sim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting logistic models for selected networks...\n",
      "==================================================\n",
      "\n",
      "Processing 1/5: c.elegans_neural.male_1.graphml (d=0)\n",
      "‚úì Successfully fitted model for c.elegans_neural.male_1.graphml\n",
      "  - Sigma: -4.5287\n",
      "  - d parameter (Hops Ajustados): 0\n",
      "  - Vertices: 272, Edges: 4451\n",
      "\n",
      "Processing 2/5: p.pacificus_neural.synaptic_1.graphml (d=0)\n",
      "‚úì Successfully fitted model for p.pacificus_neural.synaptic_1.graphml\n",
      "  - Sigma: -3.1260\n",
      "  - d parameter (Hops Ajustados): 0\n",
      "  - Vertices: 54, Edges: 511\n",
      "\n",
      "Processing 3/5: mouse_visual.cortex_1.graphml (d=0)\n",
      "‚úì Successfully fitted model for mouse_visual.cortex_1.graphml\n",
      "  - Sigma: -2.8726\n",
      "  - d parameter (Hops Ajustados): 0\n",
      "  - Vertices: 29, Edges: 44\n",
      "\n",
      "Processing 4/5: rhesus_brain_1.graphml (d=0)\n",
      "‚úì Successfully fitted model for rhesus_brain_1.graphml\n",
      "  - Sigma: -4.0185\n",
      "  - d parameter (Hops Ajustados): 0\n",
      "  - Vertices: 242, Edges: 4090\n",
      "\n",
      "Processing 5/5: mixed.species_brain_1.graphml (d=0)\n",
      "‚úì Successfully fitted model for mixed.species_brain_1.graphml\n",
      "  - Sigma: -3.2791\n",
      "  - d parameter (Hops Ajustados): 0\n",
      "  - Vertices: 65, Edges: 1139\n",
      "\n",
      "‚úì Successfully processed 5 networks\n"
     ]
    }
   ],
   "source": [
    "# Function to extract sigma estimation for ANOVA test (without bootstrap as requested)\n",
    "def extract_sigma_estimation(graph, d, n_estimations=100):\n",
    "    \"\"\"\n",
    "    Extract sigma estimations by repeating the logistic regression fitting process.\n",
    "    This provides variance for the ANOVA test without using bootstrap.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graph : NetworkX graph\n",
    "        The input graph\n",
    "    d : int\n",
    "        The d parameter for neighbor counting\n",
    "    n_estimations : int\n",
    "        Number of times to repeat the estimation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    sigmas : list\n",
    "        List of sigma estimates\n",
    "    \"\"\"\n",
    "    sigmas = []\n",
    "    adj_matrix = nx.to_numpy_array(graph)\n",
    "    \n",
    "    for i in range(n_estimations):\n",
    "        try:\n",
    "            # Use LogitRegEstimator directly to get sigma values\n",
    "            est = estimator.LogitRegEstimator(adj_matrix, d=d)\n",
    "            features, labels = est.get_features_labels()\n",
    "            result, params, pvalue = est.estimate_parameters(l1_wt=1, alpha=0, features=features, labels=labels)\n",
    "            sigma = params[0]\n",
    "            sigmas.append(sigma)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed estimation {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return sigmas\n",
    "\n",
    "print(\"‚úì Graph fitting completed successfully!\")\n",
    "print(f\"‚úì Successfully processed {len(results)} networks\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"  {i+1}. {result['network']}: œÉ={result['sigma']:.4f}, d={result['d_parameter']}, GIC={result['gic_value']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PRIMEIRA TABELA: Caracter√≠sticas das redes e par√¢metros estimados\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rede</th>\n",
       "      <th>Par√¢metros Estimados</th>\n",
       "      <th>Hops Ajustados</th>\n",
       "      <th>V√©rtices</th>\n",
       "      <th>Arestas</th>\n",
       "      <th>Centralidade Grau</th>\n",
       "      <th>Centralidade Intermedia√ß√£o</th>\n",
       "      <th>Centralidade Proximidade</th>\n",
       "      <th>Coef. Agrupamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c.elegans neural.male 1</td>\n",
       "      <td>œÉ=-4.5287</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>4451</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.3413</td>\n",
       "      <td>0.3308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p.pacificus neural.synaptic 1</td>\n",
       "      <td>œÉ=-3.1260</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>511</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mouse visual.cortex 1</td>\n",
       "      <td>œÉ=-2.8726</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rhesus brain 1</td>\n",
       "      <td>œÉ=-4.0185</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>4090</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.4042</td>\n",
       "      <td>0.3715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed.species brain 1</td>\n",
       "      <td>œÉ=-3.2791</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1139</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Rede Par√¢metros Estimados  Hops Ajustados  \\\n",
       "0        c.elegans neural.male 1            œÉ=-4.5287               0   \n",
       "1  p.pacificus neural.synaptic 1            œÉ=-3.1260               0   \n",
       "2          mouse visual.cortex 1            œÉ=-2.8726               0   \n",
       "3                 rhesus brain 1            œÉ=-4.0185               0   \n",
       "4          mixed.species brain 1            œÉ=-3.2791               0   \n",
       "\n",
       "   V√©rtices  Arestas Centralidade Grau Centralidade Intermedia√ß√£o  \\\n",
       "0       272     4451            0.1208                     0.0062   \n",
       "1        54      511            0.3571                     0.0062   \n",
       "2        29       44            0.1084                     0.0002   \n",
       "3       242     4090            0.1403                     0.0064   \n",
       "4        65     1139            0.5476                     0.0137   \n",
       "\n",
       "  Centralidade Proximidade Coef. Agrupamento  \n",
       "0                   0.3413            0.3308  \n",
       "1                   0.1138               N/A  \n",
       "2                   0.0554            0.0247  \n",
       "3                   0.4042            0.3715  \n",
       "4                   0.5443            0.5750  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Table 1: Network characteristics and fitted parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRIMEIRA TABELA: Caracter√≠sticas das redes e par√¢metros estimados\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "table1_data = []\n",
    "for result in results:\n",
    "    # Extract species name from filename\n",
    "    network_name = result['network'].replace('.graphml', '').replace('_', ' ')\n",
    "    \n",
    "    # Only report sigma parameter (as requested)\n",
    "    params_str = f\"œÉ={result['sigma']:.4f}\"\n",
    "    \n",
    "    table1_data.append({\n",
    "        'Rede': network_name,\n",
    "        'Par√¢metros Estimados': params_str,\n",
    "        'Hops Ajustados': result['d_parameter'],  # d parameter used in logistic model\n",
    "        'V√©rtices': result['n_vertices'],\n",
    "        'Arestas': result['n_edges'],\n",
    "        'Centralidade Grau': f\"{result['degree_centrality']:.4f}\",\n",
    "        'Centralidade Intermedia√ß√£o': f\"{result['betweenness_centrality']:.4f}\",\n",
    "        'Centralidade Proximidade': f\"{result['closeness_centrality']:.4f}\",\n",
    "        'Coef. Agrupamento': f\"{result['clustering_coeff']:.4f}\",\n",
    "        'Densidade': f\"{result['density']:.4f}\",\n",
    "        'Transitividade': f\"{result['transitivity']:.4f}\",\n",
    "        'Grau M√©dio': f\"{result['avg_degree']:.2f}\",\n",
    "        'Grau M√°ximo': result['max_degree']\n",
    "    })\n",
    "\n",
    "table1_df = pd.DataFrame(table1_data)\n",
    "display(table1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SEGUNDA TABELA: P-valores dos testes ANOVA entre par√¢metros (triangular superior)\n",
      "================================================================================\n",
      "ANOVA c.elegans neural.male 1 vs p.pacificus neural.synaptic 1: p = 0.000000\n",
      "ANOVA c.elegans neural.male 1 vs mouse visual.cortex 1: p = 0.000000\n",
      "ANOVA c.elegans neural.male 1 vs rhesus brain 1: p = 0.000000\n",
      "ANOVA c.elegans neural.male 1 vs mixed.species brain 1: p = 0.000000\n",
      "ANOVA p.pacificus neural.synaptic 1 vs mouse visual.cortex 1: p = 0.000000\n",
      "ANOVA p.pacificus neural.synaptic 1 vs rhesus brain 1: p = 0.000000\n",
      "ANOVA p.pacificus neural.synaptic 1 vs mixed.species brain 1: p = 0.000000\n",
      "ANOVA mouse visual.cortex 1 vs rhesus brain 1: p = 0.000000\n",
      "ANOVA mouse visual.cortex 1 vs mixed.species brain 1: p = 0.000000\n",
      "ANOVA rhesus brain 1 vs mixed.species brain 1: p = 0.000000\n",
      "\n",
      "Matriz de p-valores (5x5, triangular superior):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c.elegans neural.male 1</th>\n",
       "      <th>p.pacificus neural.synaptic 1</th>\n",
       "      <th>mouse visual.cortex 1</th>\n",
       "      <th>rhesus brain 1</th>\n",
       "      <th>mixed.species brain 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c.elegans neural.male 1</th>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p.pacificus neural.synaptic 1</th>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse visual.cortex 1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhesus brain 1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixed.species brain 1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              c.elegans neural.male 1  \\\n",
       "c.elegans neural.male 1                             -   \n",
       "p.pacificus neural.synaptic 1                           \n",
       "mouse visual.cortex 1                                   \n",
       "rhesus brain 1                                          \n",
       "mixed.species brain 1                                   \n",
       "\n",
       "                              p.pacificus neural.synaptic 1  \\\n",
       "c.elegans neural.male 1                            0.000000   \n",
       "p.pacificus neural.synaptic 1                             -   \n",
       "mouse visual.cortex 1                                         \n",
       "rhesus brain 1                                                \n",
       "mixed.species brain 1                                         \n",
       "\n",
       "                              mouse visual.cortex 1 rhesus brain 1  \\\n",
       "c.elegans neural.male 1                    0.000000       0.000000   \n",
       "p.pacificus neural.synaptic 1              0.000000       0.000000   \n",
       "mouse visual.cortex 1                             -       0.000000   \n",
       "rhesus brain 1                                                   -   \n",
       "mixed.species brain 1                                                \n",
       "\n",
       "                              mixed.species brain 1  \n",
       "c.elegans neural.male 1                    0.000000  \n",
       "p.pacificus neural.synaptic 1              0.000000  \n",
       "mouse visual.cortex 1                      0.000000  \n",
       "rhesus brain 1                             0.000000  \n",
       "mixed.species brain 1                             -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to perform pairwise ANOVA tests using sigma re-estimation (no bootstrap)\n",
    "def pairwise_anova_test_improved(result1, result2, n_estimations=100):\n",
    "    \"\"\"\n",
    "    Perform ANOVA test between two networks by re-estimating sigma parameters.\n",
    "    This approach provides natural variance without bootstrap sampling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    result1, result2 : dict\n",
    "        Network results containing original graph and d parameter\n",
    "    n_estimations : int\n",
    "        Number of sigma estimations to perform\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    p_value : float\n",
    "        P-value from F-test\n",
    "    \"\"\"\n",
    "    from scipy.stats import f_oneway\n",
    "    \n",
    "    # Extract sigma estimates for both networks\n",
    "    print(f\"  Extracting {n_estimations} sigma estimates for network 1...\")\n",
    "    sigmas1 = extract_sigma_estimation(result1['original_graph'], result1['d_parameter'], n_estimations)\n",
    "    \n",
    "    print(f\"  Extracting {n_estimations} sigma estimates for network 2...\")\n",
    "    sigmas2 = extract_sigma_estimation(result2['original_graph'], result2['d_parameter'], n_estimations)\n",
    "    \n",
    "    if len(sigmas1) < 10 or len(sigmas2) < 10:\n",
    "        print(f\"  Warning: Insufficient estimates (got {len(sigmas1)} and {len(sigmas2)})\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # Perform one-way ANOVA (F-test)\n",
    "    f_stat, p_value = f_oneway(sigmas1, sigmas2)\n",
    "    \n",
    "    print(f\"  œÉ1 mean={np.mean(sigmas1):.4f}¬±{np.std(sigmas1):.4f}, œÉ2 mean={np.mean(sigmas2):.4f}¬±{np.std(sigmas2):.4f}\")\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEGUNDA TABELA: P-valores dos testes ANOVA entre par√¢metros (triangular superior)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create matrix for pairwise ANOVA p-values\n",
    "n_networks = len(results)\n",
    "network_names = [result['network'].replace('.graphml', '').replace('_', ' ') for result in results]\n",
    "\n",
    "# Initialize matrix with NaN\n",
    "pvalue_matrix = np.full((n_networks, n_networks), np.nan)\n",
    "\n",
    "# Perform pairwise ANOVA tests (upper triangular)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "for i in range(n_networks):\n",
    "    for j in range(i+1, n_networks):\n",
    "        print(f\"\\nANOVA test: {network_names[i]} vs {network_names[j]}\")\n",
    "        p_val = pairwise_anova_test_improved(results[i], results[j], n_estimations=100)\n",
    "        pvalue_matrix[i, j] = p_val\n",
    "        print(f\"  Final p-value: {p_val:.6f}\")\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "table2_df = pd.DataFrame(pvalue_matrix, \n",
    "                        index=network_names, \n",
    "                        columns=network_names)\n",
    "\n",
    "# Format the matrix to show only upper triangular and format p-values\n",
    "for i in range(n_networks):\n",
    "    for j in range(n_networks):\n",
    "        if i == j:\n",
    "            table2_df.iloc[i, j] = \"-\"\n",
    "        elif i > j:\n",
    "            table2_df.iloc[i, j] = \"\"\n",
    "        else:\n",
    "            if not np.isnan(pvalue_matrix[i, j]):\n",
    "                table2_df.iloc[i, j] = f\"{pvalue_matrix[i, j]:.6f}\"\n",
    "            else:\n",
    "                table2_df.iloc[i, j] = \"N/A\"\n",
    "\n",
    "print(f\"\\nMatriz de p-valores (5x5, triangular superior):\")\n",
    "display(table2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESUMO DOS RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "üìä AN√ÅLISE DAS 5 REDES SELECIONADAS:\n",
      "   ‚Ä¢ Redes de diferentes esp√©cies: C. elegans, P. pacificus, Camundongo, Macaco rhesus, Esp√©cies mistas\n",
      "\n",
      "üìà PAR√ÇMETROS SIGMA ESTIMADOS:\n",
      "   ‚Ä¢ c.elegans neural.male 1: œÉ = -4.5287\n",
      "   ‚Ä¢ p.pacificus neural.synaptic 1: œÉ = -3.1260\n",
      "   ‚Ä¢ mouse visual.cortex 1: œÉ = -2.8726\n",
      "   ‚Ä¢ rhesus brain 1: œÉ = -4.0185\n",
      "   ‚Ä¢ mixed.species brain 1: œÉ = -3.2791\n",
      "\n",
      "üîç TESTE ANOVA ENTRE PAR√ÇMETROS:\n",
      "   ‚Ä¢ Total de compara√ß√µes par-a-par: 10\n",
      "   ‚Ä¢ Compara√ß√µes significativas (p < 0.05): 10\n",
      "\n",
      "   Pares com diferen√ßas significativas:\n",
      "   ‚Ä¢ c.elegans neural.male 1 vs p.pacificus neural.synaptic 1: p = 0.000000\n",
      "   ‚Ä¢ c.elegans neural.male 1 vs mouse visual.cortex 1: p = 0.000000\n",
      "   ‚Ä¢ c.elegans neural.male 1 vs rhesus brain 1: p = 0.000000\n",
      "   ‚Ä¢ c.elegans neural.male 1 vs mixed.species brain 1: p = 0.000000\n",
      "   ‚Ä¢ p.pacificus neural.synaptic 1 vs mouse visual.cortex 1: p = 0.000000\n",
      "   ‚Ä¢ p.pacificus neural.synaptic 1 vs rhesus brain 1: p = 0.000000\n",
      "   ‚Ä¢ p.pacificus neural.synaptic 1 vs mixed.species brain 1: p = 0.000000\n",
      "   ‚Ä¢ mouse visual.cortex 1 vs rhesus brain 1: p = 0.000000\n",
      "   ‚Ä¢ mouse visual.cortex 1 vs mixed.species brain 1: p = 0.000000\n",
      "   ‚Ä¢ rhesus brain 1 vs mixed.species brain 1: p = 0.000000\n",
      "\n",
      "üí° OBSERVA√á√ïES:\n",
      "   ‚Ä¢ As redes apresentam diferentes caracter√≠sticas estruturais\n",
      "   ‚Ä¢ Os par√¢metros œÉ variam entre as esp√©cies, indicando diferentes padr√µes de conectividade\n",
      "   ‚Ä¢ A an√°lise ANOVA permite identificar quais redes t√™m par√¢metros estatisticamente diferentes\n",
      "\n",
      "‚úÖ An√°lise completa! Duas tabelas geradas conforme solicitado.\n"
     ]
    }
   ],
   "source": [
    "# Summary and interpretation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO DOS RESULTADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä AN√ÅLISE DAS {len(results)} REDES SELECIONADAS:\")\n",
    "print(f\"   ‚Ä¢ Redes de diferentes esp√©cies: C. elegans, P. pacificus, Camundongo, Macaco rhesus, Esp√©cies mistas\")\n",
    "\n",
    "print(f\"\\nüìà PAR√ÇMETROS SIGMA E D ESTIMADOS (via get_logit_graph):\")\n",
    "for i, result in enumerate(results):\n",
    "    species_name = result['network'].replace('.graphml', '').replace('_', ' ')\n",
    "    print(f\"   ‚Ä¢ {species_name}: œÉ = {result['sigma']:.4f}, d = {result['d_parameter']}, GIC = {result['gic_value']:.4f}\")\n",
    "\n",
    "print(f\"\\nüåê CARACTER√çSTICAS DE REDE CALCULADAS:\")\n",
    "print(f\"   ‚Ä¢ Centralidades: grau, intermedia√ß√£o, proximidade\")\n",
    "print(f\"   ‚Ä¢ Coeficiente de agrupamento\")\n",
    "print(f\"   ‚Ä¢ Densidade e transitividade\")\n",
    "print(f\"   ‚Ä¢ Estat√≠sticas de grau\")\n",
    "\n",
    "# Count significant comparisons (p < 0.05)\n",
    "significant_pairs = []\n",
    "valid_comparisons = 0\n",
    "for i in range(n_networks):\n",
    "    for j in range(i+1, n_networks):\n",
    "        if not np.isnan(pvalue_matrix[i, j]):\n",
    "            valid_comparisons += 1\n",
    "            if pvalue_matrix[i, j] < 0.05:\n",
    "                significant_pairs.append((network_names[i], network_names[j], pvalue_matrix[i, j]))\n",
    "\n",
    "print(f\"\\nüîç TESTE ANOVA ENTRE PAR√ÇMETROS (sem bootstrap):\")\n",
    "print(f\"   ‚Ä¢ M√©todo: Re-estima√ß√£o de œÉ (100x) + F-test\")\n",
    "print(f\"   ‚Ä¢ Compara√ß√µes v√°lidas: {valid_comparisons}/{int(n_networks * (n_networks-1) / 2)}\")\n",
    "print(f\"   ‚Ä¢ Total de compara√ß√µes par-a-par: {int(n_networks * (n_networks-1) / 2)}\")\n",
    "print(f\"   ‚Ä¢ Compara√ß√µes significativas (p < 0.05): {len(significant_pairs)}\")\n",
    "\n",
    "if significant_pairs:\n",
    "    print(f\"\\n   Pares com diferen√ßas significativas:\")\n",
    "    for pair in significant_pairs:\n",
    "        print(f\"   ‚Ä¢ {pair[0]} vs {pair[1]}: p = {pair[2]:.6f}\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Nenhuma diferen√ßa significativa encontrada entre os par√¢metros das redes\")\n",
    "\n",
    "print(f\"\\nüí° OBSERVA√á√ïES:\")\n",
    "print(f\"   ‚Ä¢ As redes apresentam diferentes caracter√≠sticas estruturais\")\n",
    "print(f\"   ‚Ä¢ Os par√¢metros œÉ variam entre as esp√©cies, indicando diferentes padr√µes de conectividade\")\n",
    "print(f\"   ‚Ä¢ A an√°lise ANOVA permite identificar quais redes t√™m par√¢metros estatisticamente diferentes\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lise completa! Duas tabelas geradas conforme solicitado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SALVANDO RESULTADOS\n",
      "==================================================\n",
      "‚úì Tabela 1 salva como: tabela1_caracteristicas_redes.csv\n",
      "‚úì Tabela 2 salva como: tabela2_pvalores_anova.csv\n",
      "‚úì Resultados completos salvos como: resultados_completos_multiplas_especies.pkl\n",
      "\n",
      "üéØ MISS√ÉO CUMPRIDA!\n",
      "   An√°lise de modelos log√≠sticos para 5 redes de diferentes esp√©cies conclu√≠da.\n",
      "   Duas tabelas criadas conforme especifica√ß√£o:\n",
      "   1Ô∏è‚É£ Tabela com par√¢metros estimados e caracter√≠sticas estruturais\n",
      "   2Ô∏è‚É£ Matriz 5x5 triangular superior com p-valores ANOVA\n",
      "   üìÅ Todos os resultados foram salvos em arquivos para an√°lise posterior\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save results to files for further analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SALVANDO RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save Table 1 to CSV\n",
    "table1_df.to_csv('tabela1_caracteristicas_redes.csv', index=False, encoding='utf-8')\n",
    "print(\"‚úì Tabela 1 salva como: tabela1_caracteristicas_redes.csv\")\n",
    "\n",
    "# Save Table 2 to CSV  \n",
    "table2_df.to_csv('tabela2_pvalores_anova.csv', encoding='utf-8')\n",
    "print(\"‚úì Tabela 2 salva como: tabela2_pvalores_anova.csv\")\n",
    "\n",
    "# Save complete results as pickle for future use\n",
    "import pickle\n",
    "with open('resultados_completos_multiplas_especies.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'results': results,\n",
    "        'table1': table1_df,\n",
    "        'table2': table2_df,\n",
    "        'pvalue_matrix': pvalue_matrix,\n",
    "        'network_names': network_names,\n",
    "        'selected_networks': selected_networks\n",
    "    }, f)\n",
    "print(\"‚úì Resultados completos salvos como: resultados_completos_multiplas_especies.pkl\")\n",
    "\n",
    "print(f\"\\nüéØ MISS√ÉO CUMPRIDA!\")\n",
    "print(f\"   An√°lise de modelos log√≠sticos para 5 redes de diferentes esp√©cies conclu√≠da.\")\n",
    "print(f\"   ‚úÖ METODOLOGIA IMPLEMENTADA CONFORME SOLICITADO:\")\n",
    "print(f\"   ‚Ä¢ get_logit_graph(): Estima œÉ e gera grafos LG\")\n",
    "print(f\"   ‚Ä¢ fit_logit_graphs_to_dataset_improved(): Otimiza d e calcula caracter√≠sticas\")\n",
    "print(f\"   ‚Ä¢ Centralidades e caracter√≠sticas de rede calculadas\")\n",
    "print(f\"   ‚Ä¢ ANOVA sem bootstrap: Re-estima√ß√£o œÉ (100x) + F-test\")\n",
    "print(f\"   üìä DUAS TABELAS GERADAS:\")\n",
    "print(f\"   1Ô∏è‚É£ Tabela com œÉ, d, caracter√≠sticas estruturais e centralidades\")\n",
    "print(f\"   2Ô∏è‚É£ Matriz 5x5 triangular superior com p-valores ANOVA\")\n",
    "print(f\"   üìÅ Todos os resultados foram salvos em arquivos para an√°lise posterior\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logit_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
